{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('At', 'IN'),\n",
       " ('eight', 'CD'),\n",
       " (\"o'clock\", 'JJ'),\n",
       " ('on', 'IN'),\n",
       " ('Thursday', 'NNP'),\n",
       " ('morning', 'NN')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sentence = \"\"\"At eight o'clock on Thursday morning\n",
    "... Arthur didn't feel very good.\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tokens\n",
    "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning',\n",
    "'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged[0:6]\n",
    "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'),\n",
    "('Thursday', 'NNP'), ('morning', 'NN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'The', u'Fulton', u'County', u'Grand', u'Jury', ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "t.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lesson from Byte Academy. Leslie Cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def format_sentence(sent):\n",
    "    return {word: True for word in nltk.word_tokenize(sent)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!': True,\n",
       " 'Dogs': True,\n",
       " 'animals': True,\n",
       " 'are': True,\n",
       " 'best': True,\n",
       " 'ever': True,\n",
       " 'the': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'!': True, 'animals': True, 'are': True, 'the': True, 'ever': True, 'Dogs': True, 'best': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = []\n",
    "with open(\"/Users/macbook/GA-DSI/projects/projects-capstone/pos_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        pos.append([format_sentence(i.decode('utf-8')), 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg = []\n",
    "with open(\"/Users/macbook/GA-DSI/projects/projects-capstone/neg_tweets.txt\") as f:\n",
    "    for i in f: \n",
    "        neg.append([format_sentence(i.decode('utf-8')), 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pos[:int((.9)*len(pos))] + neg[:int((.9)*len(neg))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pos[int((.9)*len(pos)):] + neg[int((.9)*len(neg)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      no = True              neg : pos    =     20.6 : 1.0\n",
      "                 awesome = True              pos : neg    =     18.7 : 1.0\n",
      "                headache = True              neg : pos    =     18.0 : 1.0\n",
      "               beautiful = True              pos : neg    =     14.2 : 1.0\n",
      "                    love = True              pos : neg    =     14.2 : 1.0\n",
      "                      Hi = True              pos : neg    =     12.7 : 1.0\n",
      "                    glad = True              pos : neg    =      9.7 : 1.0\n",
      "                   Thank = True              pos : neg    =      9.7 : 1.0\n",
      "                     fan = True              pos : neg    =      9.7 : 1.0\n",
      "                    lost = True              neg : pos    =      9.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "# To see if the classifier is accurate\n",
    "\n",
    "example1 = \"this workshop is awesome.\"\n",
    "\n",
    "print classifier.classify(format_sentence(example1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "# To see if the classifier is accurate\n",
    "example2 = \"this workshop is awful.\"\n",
    "\n",
    "print classifier.classify(format_sentence(example2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865671641791\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "print accuracy(classifier, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "# Neutral\n",
    "example3 = \"the weather is OK\"\n",
    "print classifier.classify(format_sentence(example3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambiguity\n",
    "Skipped down to 4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'QL'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "unigram_tagger.tag(brown_sents[2007])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Various', u'JJ'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'apartments', u'NNS'),\n",
       " (u'are', u'BER'),\n",
       " (u'of', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'terrace', u'NN'),\n",
       " (u'type', u'NN'),\n",
       " (u',', u','),\n",
       " (u'being', u'BEG'),\n",
       " (u'on', u'IN'),\n",
       " (u'the', u'AT'),\n",
       " (u'ground', u'NN'),\n",
       " (u'floor', u'NN'),\n",
       " (u'so', u'CS'),\n",
       " (u'that', u'CS'),\n",
       " (u'entrance', u'NN'),\n",
       " (u'is', u'BEZ'),\n",
       " (u'direct', u'JJ'),\n",
       " (u'.', u'.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(brown_tagged_sents)\n",
    "bigram_tagger.tag(brown_sents[2007])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back up to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'\\python')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.compile(\"\\python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match at 0x11587e8b8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(\"\\python\")\n",
    "re.match(p, \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(re.match(p,\"python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = re.compile('[pP]ython')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('awesome', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.word_tokenize(\"Python is an awesome language!\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omg', ',', 'natural', 'language', 'processing', 'is', 'so', 'cool', 'and', 'i', \"'m\", 'really', 'enjoying', 'this', 'workshop', '!']\n"
     ]
    }
   ],
   "source": [
    "raw = \"OMG, Natural Language Processing is SO cool and I'm really enjoying this workshop!\"\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "tokens = [i.lower() for i in tokens]\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Lancaster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['omg', ',', 'nat', 'langu', 'process', 'is', 'so', 'cool', 'and', 'i', \"'m\", 'real', 'enjoy', 'thi', 'workshop', '!']\n"
     ]
    }
   ],
   "source": [
    "lancaster = nltk.LancasterStemmer()\n",
    "stems = [lancaster.stem(i) for i in tokens]\n",
    "print stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'omg', u',', u'natur', u'languag', u'process', u'is', u'so', u'cool', u'and', u'i', u\"'m\", u'realli', u'enjoy', u'thi', u'workshop', u'!']\n"
     ]
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "stem = [porter.stem(i) for i in tokens]\n",
    "print stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'woman', 'in', 'technology', 'are', 'amazing', 'at', 'coding']\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "text = \"Women in technology are amazing at coding\"\n",
    "ex = [i.lower() for i in text.split()]\n",
    "\n",
    "lemmas = [lemma.lemmatize(i) for i in ex]\n",
    "print lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
