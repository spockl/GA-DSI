{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Webscraping Project 4 Lab\n",
    "\n",
    "Week 4 | Day 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary predictor with Logistic Regression.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com (or other sites at your team's discretion). In the second part, the focus is on using listings with salary information to build a model and predict high or low salaries and what features are predictive of that result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### DO NOT RUN ###\n",
    "# Non-iterating functions\n",
    "\n",
    "i = requests.get(URL)\n",
    "i_soup = BeautifulSoup(i.content, 'lxml')\n",
    "i_soup\n",
    "\n",
    "def extract_location_from_some_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(\"span\", class_=\"location\").text\n",
    "    except:\n",
    "        return np.nan\n",
    "    return some_some.find\n",
    "print 'location: ', extract_location_from_some_soup(i_soup)\n",
    "\n",
    "def extract_title_from_some_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find('a', {'data-tn-element': 'jobTitle'}).text\n",
    "    except:\n",
    "        return np.nan\n",
    "    return some_soup.find\n",
    "print 'title: ', extract_title_from_some_soup(i_soup)\n",
    "\n",
    "def extract_company_from_some_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(\"span\", class_=\"company\").text.strip()\n",
    "    except:\n",
    "        return np.nan\n",
    "    return some_soup.find\n",
    "print 'company: ', extract_company_from_some_soup(i_soup)\n",
    "\n",
    "def extract_salary_from_some_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find('tr', class_='snip').text\n",
    "    except:\n",
    "        return np.nan\n",
    "    return some_some.find\n",
    "print 'salary: ', extract_salary_from_some_soup(i_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to extract location, job title, company, salary and description\n",
    "\n",
    "# extract location\n",
    "def extract_location_from_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(\"span\", class_=\"location\").text\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# extract job title\n",
    "def extract_title_from_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(class_=\"jobtitle\").text.strip()\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "# extract location\n",
    "def extract_company_from_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(\"span\", class_=\"company\").text.strip()\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "#extract salary 2 (salary_dffunction)\n",
    "def extract_salary_from_soup_2(some_soup):\n",
    "    for i in some_soup.findAll(\"div\", class_=\"sjcl\"):\n",
    "        try:\n",
    "            for item in i.find(\"div\"):\n",
    "                return item.strip()\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "#extract salary\n",
    "def extract_salary_from_soup(some_soup):\n",
    "    for i in some_soup.findAll(\"td\", class_=\"snip\"):\n",
    "        try:\n",
    "            for item in i.find(\"nobr\"):\n",
    "                return item.strip()\n",
    "        except:\n",
    "            return extract_salary_from_soup_2(some_soup)\n",
    "        \n",
    "# extract description\n",
    "def extract_description_from_soup(some_soup):\n",
    "    try:\n",
    "        return some_soup.find(\"span\", class_=\"summary\").text.strip()\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of results from website search\n",
    "\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 400\n",
    "\n",
    "my_cities = ['New+York', 'San+Francisco', 'Seattle', 'San+Jose', 'Austin', 'Boston', \\\n",
    "             'Denver', 'Boulder', 'Minneapolis-Saint+Paul', 'Atlanta']\n",
    "results = []\n",
    "page_count = 0\n",
    "results_pp = []\n",
    "for city in set(my_cities):\n",
    "    for start in range(0,max_results_per_city,10):\n",
    "        URL = url_template.format(city,start)\n",
    "        r = requests.get(URL)\n",
    "        indeed_soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        results.append(indeed_soup)\n",
    "        page_count+=1\n",
    "        results_pp.append(len(indeed_soup.findAll(\"div\", class_=\"result\")))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Append search results into lists\n",
    "\n",
    "location = []\n",
    "title = []\n",
    "company = []\n",
    "salary = []\n",
    "description = []\n",
    "for page in results:\n",
    "        for result in page.findAll(\"div\", class_=\"result\"):\n",
    "            location.append(extract_location_from_soup(result))\n",
    "            title.append(extract_title_from_soup(result))\n",
    "            company.append(extract_company_from_soup(result))\n",
    "            salary.append(extract_salary_from_soup(result))\n",
    "            description.append(extract_description_from_soup(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print len(location)\n",
    "print len(title)\n",
    "print len(company)\n",
    "print len(salary)\n",
    "print len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>result_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austin</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boston</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denver</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Minneapolis-Saint+Paul</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New+York</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San+Jose</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     city  result_count\n",
       "0                 Atlanta           600\n",
       "1                  Austin           600\n",
       "2                  Boston           600\n",
       "3                 Boulder           600\n",
       "4                  Denver           600\n",
       "5  Minneapolis-Saint+Paul           600\n",
       "6                New+York           600\n",
       "7           San+Francisco           600\n",
       "8                San+Jose           600\n",
       "9                 Seattle           600"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes the number of results per city is inconsitent\n",
    "# Create df to calculate actual number of results per city\n",
    "\n",
    "city_pages = []\n",
    "for city in set(my_cities):\n",
    "    for i in range(int(max_results_per_city)/10):\n",
    "        city_pages.append(city)\n",
    "city_count = pd.DataFrame({'city':city_pages, 'result_count':results_pp})\n",
    "city_count = city_count.groupby([\"city\"])[\"result_count\"].agg(np.sum).to_frame().reset_index()\n",
    "city_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of cities (as location in search results do not always match exact search terms)\n",
    "\n",
    "city_list =[]\n",
    "for city in set(my_cities):\n",
    "    for i in range(city_count[city_count[\"city\"]==city][\"result_count\"]):\n",
    "        city_list.append(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>EXL</td>\n",
       "      <td>Manager, Decision Analytics Services</td>\n",
       "      <td>None</td>\n",
       "      <td>Our global footprint of nearly 2,000 data scie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>RangTech</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Web analytics, Data mining techniques applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>New+York</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>ISO</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Lead Data Scientist. Lead research, evaluation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Memorial Sloan Kettering</td>\n",
       "      <td>Data Scientist, Imaging Informatics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MSK is seeking an Imaging Informatics Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Booking.com</td>\n",
       "      <td>Data Scientist - Relocation to China (Chinese ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist – China Localisation. Data Scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city         location                   company  \\\n",
       "5995  New+York  Jersey City, NJ                       EXL   \n",
       "5996  New+York     New York, NY                  RangTech   \n",
       "5997  New+York  Jersey City, NJ                       ISO   \n",
       "5998  New+York     New York, NY  Memorial Sloan Kettering   \n",
       "5999  New+York     New York, NY               Booking.com   \n",
       "\n",
       "                                                  title salary  \\\n",
       "5995               Manager, Decision Analytics Services   None   \n",
       "5996                                     Data Scientist   None   \n",
       "5997                                Lead Data Scientist   None   \n",
       "5998                Data Scientist, Imaging Informatics    NaN   \n",
       "5999  Data Scientist - Relocation to China (Chinese ...    NaN   \n",
       "\n",
       "                                            description  \n",
       "5995  Our global footprint of nearly 2,000 data scie...  \n",
       "5996  Web analytics, Data mining techniques applicat...  \n",
       "5997  Lead Data Scientist. Lead research, evaluation...  \n",
       "5998  MSK is seeking an Imaging Informatics Data Sci...  \n",
       "5999  Data Scientist – China Localisation. Data Scie...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df of all search results\n",
    "\n",
    "df = pd.DataFrame(zip(city_list, location, company, title, salary, description))\n",
    "df.columns = [\"city\", \"location\", \"company\", \"title\", \"salary\", \"description\"]\n",
    "print df.shape\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Broomfield, CO 80021</td>\n",
       "      <td>Return Path</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Data Scientist will work closely with othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>RefactorU</td>\n",
       "      <td>Data Scientist (Curriculum Developer / Instruc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RefactorU is looking for one or more talented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Centennial, CO</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data structures, data representation, data cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>CaliberMind</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$120,000 a year</td>\n",
       "      <td>The Chief Data Scientist is a critical role in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>RefactorU</td>\n",
       "      <td>Data Scientist (Curriculum Developer / Instruc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RefactorU is looking for one or more talented ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city              location      company  \\\n",
       "0  Boulder  Broomfield, CO 80021  Return Path   \n",
       "1  Boulder           Boulder, CO    RefactorU   \n",
       "2  Boulder        Centennial, CO      Pearson   \n",
       "3  Boulder           Boulder, CO  CaliberMind   \n",
       "4  Boulder           Boulder, CO    RefactorU   \n",
       "\n",
       "                                               title           salary  \\\n",
       "0                                     Data Scientist              NaN   \n",
       "1  Data Scientist (Curriculum Developer / Instruc...              NaN   \n",
       "2                          Machine Learning Engineer              NaN   \n",
       "3                              Senior Data Scientist  $120,000 a year   \n",
       "4  Data Scientist (Curriculum Developer / Instruc...              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  The Data Scientist will work closely with othe...  \n",
       "1  RefactorU is looking for one or more talented ...  \n",
       "2  Data structures, data representation, data cle...  \n",
       "3  The Chief Data Scientist is a critical role in...  \n",
       "4  RefactorU is looking for one or more talented ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace None in salary column with np.nan\n",
    "\n",
    "def replace_none(x):\n",
    "    if x == None:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df = df.applymap(replace_none)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3316, 6)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates from df\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Boston                    405\n",
       "San+Jose                  404\n",
       "Seattle                   404\n",
       "New+York                  404\n",
       "San+Francisco             401\n",
       "Denver                    347\n",
       "Boulder                   312\n",
       "Atlanta                   298\n",
       "Austin                    171\n",
       "Minneapolis-Saint+Paul    170\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"city\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a separate salary df for only entries with yearly salary\n",
    "\n",
    "salary_df = df[~df[\"salary\"].isnull()]\n",
    "salary_df = salary_df[salary_df[\"salary\"].str.contains(\"year\")]\n",
    "salary_df.reset_index(inplace=True, drop=True)\n",
    "salary_df[\"salary\"] = salary_df[\"salary\"].apply(lambda x: x.replace(\"a year\",\"\"))\n",
    "salary_df[\"salary\"]= salary_df[\"salary\"].apply(lambda x: (str(x)).split('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create field for average salary if salary is a range\n",
    "\n",
    "salary_df[\"low_range\"] = salary_df[\"salary\"].apply(lambda x: x[0].replace(\"$\",\"\").replace(\",\",\"\")).astype(int)\n",
    "salary_df[\"high_range\"] = salary_df[\"salary\"].apply(lambda x: x[-1].replace(\"$\",\"\").replace(\",\",\"\")).astype(int)\n",
    "salary_df[\"avg\"] = (salary_df[\"low_range\"] + salary_df[\"high_range\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job listings with salary info: 119\n",
      "Total job listings:  3316\n",
      "Salaried listings / Total listings 3.589 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>low_range</th>\n",
       "      <th>high_range</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>CaliberMind</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>[$120,000 ]</td>\n",
       "      <td>The Chief Data Scientist is a critical role in...</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000</td>\n",
       "      <td>120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boulder</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Managing Director for STROBE</td>\n",
       "      <td>[$100,000 ,  $115,000 ]</td>\n",
       "      <td>Of visiting scientists; In use of excel, data ...</td>\n",
       "      <td>100000</td>\n",
       "      <td>115000</td>\n",
       "      <td>107500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city     location                 company                         title  \\\n",
       "0  Boulder  Boulder, CO             CaliberMind         Senior Data Scientist   \n",
       "1  Boulder  Boulder, CO  University of Colorado  Managing Director for STROBE   \n",
       "\n",
       "                    salary                                        description  \\\n",
       "0              [$120,000 ]  The Chief Data Scientist is a critical role in...   \n",
       "1  [$100,000 ,  $115,000 ]  Of visiting scientists; In use of excel, data ...   \n",
       "\n",
       "   low_range  high_range       avg  \n",
       "0     120000      120000  120000.0  \n",
       "1     100000      115000  107500.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Job listings with salary info:\", len(salary_df)\n",
    "print \"Total job listings: \", len(df)\n",
    "print \"Salaried listings / Total listings\", round((float(len(salary_df)) / len(df)) * 100, 3), '%'\n",
    "salary_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>low_range</th>\n",
       "      <th>high_range</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Beeswax</td>\n",
       "      <td>Senior / Director Data Science</td>\n",
       "      <td>[$130,000 ,  $165,000 ]</td>\n",
       "      <td>A minimum of 5 years experience in Machine lea...</td>\n",
       "      <td>130000</td>\n",
       "      <td>165000</td>\n",
       "      <td>147500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Averity</td>\n",
       "      <td>Senior Data Scientist for Hedge Fund</td>\n",
       "      <td>[$150,000 ,  $250,000 ]</td>\n",
       "      <td>Are you Senior Data Scientist looking to join ...</td>\n",
       "      <td>150000</td>\n",
       "      <td>250000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Harnham</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>[$110,000 ]</td>\n",
       "      <td>You will join the data engineering team and wo...</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>Senior Research Staff Assistant</td>\n",
       "      <td>[$50,000 ]</td>\n",
       "      <td>Work with scientists to conduct quality contro...</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>New+York</td>\n",
       "      <td>New York, NY 10018 (Clinton area)</td>\n",
       "      <td>ingenium</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>[$200,000 ]</td>\n",
       "      <td>Lead and manage a team of data engineers and s...</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city                           location              company  \\\n",
       "114  New+York                       New York, NY              Beeswax   \n",
       "115  New+York                       New York, NY              Averity   \n",
       "116  New+York                       New York, NY              Harnham   \n",
       "117  New+York                       New York, NY  Columbia University   \n",
       "118  New+York  New York, NY 10018 (Clinton area)             ingenium   \n",
       "\n",
       "                                    title                   salary  \\\n",
       "114        Senior / Director Data Science  [$130,000 ,  $165,000 ]   \n",
       "115  Senior Data Scientist for Hedge Fund  [$150,000 ,  $250,000 ]   \n",
       "116                     Big Data Engineer              [$110,000 ]   \n",
       "117       Senior Research Staff Assistant               [$50,000 ]   \n",
       "118                    Lead Data Engineer              [$200,000 ]   \n",
       "\n",
       "                                           description  low_range  high_range  \\\n",
       "114  A minimum of 5 years experience in Machine lea...     130000      165000   \n",
       "115  Are you Senior Data Scientist looking to join ...     150000      250000   \n",
       "116  You will join the data engineering team and wo...     110000      110000   \n",
       "117  Work with scientists to conduct quality contro...      50000       50000   \n",
       "118  Lead and manage a team of data engineers and s...     200000      200000   \n",
       "\n",
       "          avg  \n",
       "114  147500.0  \n",
       "115  200000.0  \n",
       "116  110000.0  \n",
       "117   50000.0  \n",
       "118  200000.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new csv with salary_df\n",
    "\n",
    "cols = salary_df.columns\n",
    "salary_df[cols].to_csv(\"indeed_salary.csv\", encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
