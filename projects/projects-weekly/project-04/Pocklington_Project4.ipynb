{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import neccesary programs\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for getting location from indeed\n",
    "\n",
    "def extract_location_from_result(loc):\n",
    "    try:\n",
    "        for n in loc.findAll(class_='location'):\n",
    "            return n.text.strip()\n",
    "    except:\n",
    "        return 'None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for getting company from indeed\n",
    "\n",
    "def extract_company_from_result(comp):\n",
    "    try:\n",
    "        for n in comp.findAll(class_='company'):\n",
    "            return n.text.strip()\n",
    "    except:\n",
    "        return 'None' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for getting job title from indeed\n",
    "\n",
    "def extract_jobtitle_from_result(jobtitle):\n",
    "    try:\n",
    "        for n in jobtitle.findAll(class_='jobtitle'):\n",
    "            return n.text.strip()\n",
    "    except:\n",
    "        return 'None'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get salary from indeed\n",
    "\n",
    "def extract_salary_from_result(sal):\n",
    "    try:\n",
    "        for n in sal.findAll('td', class_='snip'):\n",
    "            return n.nobr\n",
    "    except:\n",
    "        return 'None' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to get summary/description from indeed\n",
    "\n",
    "def extract_summary_from_result(desc):\n",
    "    try:\n",
    "        for n in desc.findAll('span', class_='summary'):\n",
    "            return n.text.strip()\n",
    "    except:\n",
    "        return 'None' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Location = []\n",
    "Job_Title = []\n",
    "Company = []\n",
    "Salary = []\n",
    "Description = []\n",
    "\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100\n",
    "cities = ['New+York', 'Chicago', 'Boston', 'San+Francisco', 'Los+Angeles', 'Austin', 'Atlanta']\n",
    "results = []\n",
    "for city in set(cities):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        url = url_template.format(city,start)\n",
    "        ru = requests.get(url)\n",
    "        indeed = BeautifulSoup(ru.content, \"lxml\")\n",
    "        for item in indeed.findAll('div', class_='result'):\n",
    "            Location.append(extract_location_from_result(item))\n",
    "            Job_Title.append(extract_jobtitle_from_result(item))\n",
    "            Company.append(extract_company_from_result(item))\n",
    "            Salary.append(extract_salary_from_result(item))\n",
    "            Description.append(extract_summary_from_result(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataframe and name columns. Include Cities\n",
    "df = pd.DataFrame([Location,Job_Title,Company,Salary,Description]).T \n",
    "  \n",
    "df.columns= ['Location','Job_Title','Company','Salary','Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['City'] = lambda x: pd.series([c for c in ('Location')(c.split(','))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df.row.str.split(' ',1).tolist(),\n",
    "                                   columns = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-dd952af3daa7>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-dd952af3daa7>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    columns = ['Cities','Location'])\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df['Location'.str.split(' ',1).tolist(),\n",
    "                                   columns = ['Cities','Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Salary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows with no salary\n",
    "df = df[df.Salary.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove excess salary info\n",
    "df['Salary'] = df['Salary'].apply(lambda x: str(x))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: x.replace('$',''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: x.replace(',',''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: x.replace('<nobr>',''))\n",
    "df['Salary'] = df['Salary'].apply(lambda x: x.replace('</nobr>',''))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset index\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse yearly, monthly, hourly salaries\n",
    "df['hourly_sal'] = df['Salary'].map(lambda x: 1 if 'hour' in x else 0)\n",
    "\n",
    "df['monthly_sal'] = df['Salary'].map(lambda x: 1 if 'month' in x else 0)\n",
    "\n",
    "df['yearly_sal'] = df['Salary'].map(lambda x: 1 if 'year' in x else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop monthly and hourly salaries\n",
    "df_year1 = df[df.monthly_sal != 1]\n",
    "df_year = df_year1[df.hourly_sal !=1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop columns hourly_sal, monthly_sal, and yearly_sal\n",
    "df_year = df_year.drop('hourly_sal', axis=1)\n",
    "df_year = df_year.drop('monthly_sal', axis=1)\n",
    "df_year = df_year.drop('yearly_sal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for unique Salary values\n",
    "df_year['Salary'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset index and set dataframe to df\n",
    "df = df_year.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove non-numeric Salary elements\n",
    "df['Salary'] = df['Salary'].str.replace('a year', '')\n",
    "df['Salary'] = df['Salary'].str.replace('-', ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for other non-numeric values\n",
    "df['Salary'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove '1250 a week'\n",
    "\n",
    "df = df[df.Salary.str.contains('1250') == False]\n",
    "df['Salary'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.get_dummies(df,columns = ['Location','Job_Title','Company'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 77) ## create train-test out of the data given\n",
    "\"\"\" Fit a binary classification predictor.\"\"\"\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "C_vals = [0.0001, 0.001, 0.01, 0.1, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "gs = GridSearchCV(logreg, {'penalty': penalties, 'C': C_vals}, verbose=False, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "lr = LogisticRegressionCV(Cs=10, cv=5)\n",
    "cv_model = logreg.fit(X_train, y_train)\n",
    "cv_pred = cv_model.predict(X_test)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "y_score = lr.decision_function(X_test) # Submit these response, the output of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conmat = np.array(confusion_matrix(Y_test, y_pred, labels=[1,0]))\n",
    "confusion = pd.DataFrame(conmat, index=['over_50k', 'under_50k'],\n",
    "                            columns=['predicted_over50k','predicted_under50k'])\n",
    "\n",
    "print(confusion)\n",
    "print classification_report(Y_test,y_pred)\n",
    "roc_auc_score(Y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef = pd.DataFrame([X.columns.values.tolist(), lr.coef_[0].tolist()], index=['features', 'coef']).T\n",
    "coef.sort_values(by='coef', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
